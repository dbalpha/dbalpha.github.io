<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>虚拟机和容器化的区别</title>
    <link href="/2022/02/21/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2022/02/21/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="虚拟机和容器化的区别"><a href="#虚拟机和容器化的区别" class="headerlink" title="虚拟机和容器化的区别"></a>虚拟机和容器化的区别</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>随着容易化越来越流行，但是很多人对容器基本原理不是太了解，各种文档和产品介绍上也是把容器和虚拟机拿来做比较，导致很多人把容器化误认为是虚拟化的一个升级，这是完全错误的一个概念，从实现原理上来讲容器化和虚拟化是2个完全不同的技术，虚拟化≠容器化，只是2个技术的有想要达到的共同目的，任务隔离</p><h2 id="1、虚拟技术"><a href="#1、虚拟技术" class="headerlink" title="1、虚拟技术"></a>1、虚拟技术</h2><p>下图是应用程序在虚拟机上运行的示意图<br><img src=".%5C%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB%5Cvirtual-machine-architecture-1.jpg" alt="虚拟技术"></p><p>让我们从下至上分析下各个层:</p><ul><li><p>基础设施层</p><p>基础设施层，也就是宿主机层，可以是运行在机房的服务，也可是虚拟云上的虚拟机（如阿里云，Azure或者Amazon ），甚至可以是一台笔记本。</p></li><li><p>操作系统层</p><p>操作系统就是操作系统啦，我不信你不懂。</p></li><li><p>hypervisor层</p><p>hypervisor也称为虚拟机监视器（virtual machine monitor 、缩写VMM），虚拟机可以理解为一个封装在文件中的操作系统，我们还需要一个能运行这些文件程序，比较流行的hypervisor有MacOS上的HyperKit，window的Hyper-V和linux的KVM，还有VirtualBox 和d VMWare。</p></li><li><p>操作系统层</p><p>不需多说了吧，windows、Linux、MacOS……。</p></li><li><p>运行库层</p><p>这一层就是在操作系统上面安装的各种二进制文件和依赖库，比如你要运行python，拿你就需要安装python依赖库，运行java程序就需要安装JDK，其他的像C语言依赖库，ruby依赖库等等。</p></li><li><p>应用程序层</p><p>这一层就是你所运行程序的源代码或是编译后的文件，如果你想做程序间的隔离，你需要将他们运行在各自的虚拟机中。</p></li></ul><h2 id="2、容器技术"><a href="#2、容器技术" class="headerlink" title="2、容器技术"></a>2、容器技术</h2><p>  下图是程序在容器内运行的示意图</p><p><img src=".%5C%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB%5Cdocker-architecture-1.jpg" alt="blog/docker-architecture.jpg"></p><p>  从架构示意图中可以明显的看出轻薄了，少了一层guest OS，我也从下至上分析下各层</p><ul><li><p>基础设施层</p><p>这一层和上面虚拟机并没有什么不同，任何系统的运行都需要计算机的承载</p></li><li><p>操作系统层</p><p>任何可以运行docker的操作系统，主流的Linux发行版都支持docke，在Windows和MacOS上也有运行docker的方法</p></li><li><p>Docker daemon 层</p><p>这一层替换了虚拟化中的hypervisor层，他负责管理Docker的对象，如镜像、容器、数据卷、网络。</p><p>Docker daemon与其它Docker daemon交互以管理容器的服务。</p><p>运行库层</p></li><li><p>运行库层</p><p>和虚级化一样需要各种依赖库，只是他们被打包成了docker镜像，然后docker守护进程运行他们。</p></li><li><p>应用程序层</p><p>应用程序和他们的依赖库被打包到Docker镜像中，不同的应用被打包不同的镜像中，然后他们各自运行在不同的Docker中，他们是相互隔离的。</p></li></ul><h2 id="3、Docker和虚拟机对比"><a href="#3、Docker和虚拟机对比" class="headerlink" title="3、Docker和虚拟机对比"></a>3、Docker和虚拟机对比</h2><p>Docker daemon可以直接和主机操作系统通信，并负责为Docker容器分配资源；它还负责主机操作系统与容器，容器与容器之间的隔离。</p><p>容器的启动要快的多，通常是几毫秒就可以了，而虚拟机通常都需要数分钟</p><p>容器还可以节省大量磁盘空间和其他系统资源，因为他不需要额外的操作系统了；Docker不需要虚拟化，他是直接运行在操作系统上。</p><p>虽然容器化有很多优势，但是并不能否定虚拟机技术，在一些场景下虚拟机是无法被取代的。</p><p>虚拟技术对可以对整个资源和工作环境进行隔了。例如，云供应商使用虚拟机技术隔离不同的用户，docker更多是用来应用之间的隔离，最常见的是把一堆应用打包到各自镜像中运行，微服务架构常见的场景</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>微服务探索</title>
    <link href="/2022/02/21/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8E%A2%E7%B4%A2/"/>
    <url>/2022/02/21/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8E%A2%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="为什要做微服务"><a href="#为什要做微服务" class="headerlink" title="为什要做微服务?"></a>为什要做微服务?</h1><p>1、数据模型变更带来的影响更小，通过微服务架构在各个服务之间做好隔离，上下游的服务对接通过微服务的接口来进行</p><p>2、底层组件的变动更容易，比如某个服务需要加缓存</p><p>3、代码复用</p><p>4、便于扩容，可以根据服务压力精准扩容</p><h1 id="微服务为什么要容器化"><a href="#微服务为什么要容器化" class="headerlink" title="微服务为什么要容器化"></a>微服务为什么要容器化</h1><p>1、单体应用拆分成多个微服务后，可以快速的迭代和开发，但是带来个更多测试和运维成本的提升。比如之前是一个打的单体应用，在部署的时候只要打包成一个大的war包部署到web中间件（比如tomcat）中即可，拆分成多个微服务后，就有好多微服务需要打包和部署，如果继续采用之前的location部署的模式，会带来各种问题，比如一台机器部署多个微服务，需要注意端口冲突、路径和文件命名冲突以及资源争抢等问题，如果新增一个微服务的部署，还要考虑新的服务要部署在哪个机器上，并且服务的亲和和非亲和问题难以控制，容器化就很好的解决了这些问题</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Docker常见扫盲问题</title>
    <link href="/2022/02/21/Docker%E5%B8%B8%E8%A7%81%E6%89%AB%E7%9B%B2%E9%97%AE%E9%A2%98/"/>
    <url>/2022/02/21/Docker%E5%B8%B8%E8%A7%81%E6%89%AB%E7%9B%B2%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="Docker-常见扫盲问题"><a href="#Docker-常见扫盲问题" class="headerlink" title="Docker 常见扫盲问题"></a>Docker 常见扫盲问题</h1><ol><li> Docker 和虚拟机有啥不同？</li></ol><p>   答：Docker 是轻量级的沙盒，在其中运行的只是应用，虚拟机里面还有额外的系统。 </p><ol start="2"><li><p>Docker 安全么？<br>答：Docker 利用了 Linux 内核中很多安全特性来保证不同容器之间的隔离，并且通过签名机制来对镜像进行验证。大量生产环境的部署证明，Docker 虽然隔离性无法与虚拟机相比，但仍然具有极高的安全性。 </p></li><li><p> 如何清理后台停止的容器？ </p></li></ol><p>   答：可以使用 sudo docker rm $sudo( docker ps -a -q) 命令。 </p><ol start="4"><li><p>如何查看镜像支持的环境变量？<br>答：可以使用 docker run IMAGE env 命令。 </p></li><li><p>当启动容器的时候提示：exec format error？如何解决问题<br>答：检查启动命令是否有可执行权限，进入容器手工运行脚本进行排查。 </p></li><li><p>本地的镜像文件都存放在哪里？<br>答：与 Docker 相关的本地资源都存放在/var/lib/docker/目录下，其中 container 目录存放容器信息，graph 目录存放镜像信息，aufs 目录下存放具体的内容文件。 </p></li><li><p>如何退出一个镜像的 bash，而不终止它？<br>答：按 Ctrl-p Ctrl-q。 </p></li><li><p>退出容器时候自动删除?<br>答：使用 –rm 选项，例如 sudo docker run –rm -it ubuntu </p></li><li><p>怎么快速查看本地的镜像和容器？<br>答：可以通过 docker images 来快速查看本地镜像；通过 docker ps -a 快速查看本<br>地容器。 </p></li></ol><p>镜像相关： </p><ol><li><p>如何批量清理临时镜像文件？<br>答：可以使用 sudo docker rmi $(sudo docker images -q -f danging=true)命令 </p></li><li><p>如何查看镜像支持的环境变量？<br>答：使用 sudo docker run IMAGE env </p></li><li><p>本地的镜像文件都存放在哪里<br>答：于 Docker 相关的本地资源存放在/var/lib/docker/目录下，其中 container 目录<br>存放容器信息，graph 目录存放镜像信息，aufs 目录下存放具体的镜像底层文件。 </p></li><li><p>构建 Docker 镜像应该遵循哪些原则？<br>答：整体远侧上，尽量保持镜像功能的明确和内容的精简，要点包括：<br>l  尽量选取满足需求但较小的基础系统镜像，建议选择 debian:wheezy 镜像，仅有<br>86MB 大小<br>l  清理编译生成文件、安装包的缓存等临时文件<br>l  安装各个软件时候要指定准确的版本号，并避免引入不需要的依赖<br>l  从安全的角度考虑，应用尽量使用系统的库和依赖<br>l  使用 Dockerfile 创建镜像时候要添加.dockerignore 文件或使用干净的工作目录 </p></li></ol><p>容器相关 </p><ol><li><p>容器退出后，通过 docker ps 命令查看不到，数据会丢失么？<br>答：容器退出后会处于终止（exited）状态，此时可以通过 docker ps -a 查看，其中数据不会丢失，还可以通过 docker start 来启动，只有删除容器才会清除数据。 </p></li><li><p>如何停止所有正在运行的容器？<br>答：使用 docker kill $(sudo docker ps -q) </p></li><li><p>如何清理批量后台停止的容器？<br>答：使用 docker rm $（sudo docker ps -a -q） </p></li><li><p>如何临时退出一个正在交互的容器的终端，而不终止它？<br>答：按 Ctrl+p，后按 Ctrl+q，如果按 Ctrl+c 会使容器内的应用进程终止，进而会使容器终止。 </p></li><li><p>很多应用容器都是默认后台运行的，怎么查看它们的输出和日志信息？<br>答：使用 docker logs，后面跟容器的名称或者 ID 信息 </p></li><li><p>使用 docker port 命令映射容器的端口时，系统报错 Error: No public port ‘80’ published for …，是什么意思？<br>答：创建镜像时 Dockerfile 要指定正确的 EXPOSE 的端口，容器启动时指定PublishAllport=true </p></li><li><p>可以在一个容器中同时运行多个应用进程吗？<br>答：一般不推荐在同一个容器内运行多个应用进程，如果有类似需求，可以通过额外的进程管理机制，比如 supervisord 来管理所运行的进程 </p></li><li><p>如何控制容器占用系统资源（CPU，内存）的份额？<br>答：在使用 docker  create 命令创建容器或使用 docker  run  创建并运行容器的时候，可以使用-c|–cpu-shares[=0]参数来调整同期使用 CPU 的权重，使用m|–memory参数来调整容器使用内存的大小。 </p></li></ol><p>仓库相关 </p><ol><li><p>仓库（Repository）、注册服务器（Registry）、注册索引（Index）有何关系？<br>答：首先，仓库是存放一组关联镜像的集合，比如同一个应用的不同版本的镜像，注册服务器是存放实际的镜像的地方，注册索引则负责维护用户的账号，权限，搜索，标签等管理。注册服务器利用注册索引来实现认证等管理。 </p></li><li><p>从非官方仓库（如：<a href="http://dl.dockerpool.com）下载镜像的时候，有时候会提示“Error：Invaild">http://dl.dockerpool.com）下载镜像的时候，有时候会提示“Error：Invaild</a> registry endpoint <a href="https://dl.docker.com:5000/v1/%E2%80%A6%E2%80%9D">https://dl.docker.com:5000/v1/…”</a>?<br>答：Docker 自 1.3.0 版本往后以来，加强了对镜像安全性的验证，需要手动添加对非官方仓库的信任。 DOCKER_OPTS=”–insecure-registry dl.dockerpool.com:5000”<br>重启 docker 服务 </p></li></ol><p>配置相关 </p><ol><li><p>Docker 的配置文件放在那里。如何修改配置？<br>答：Ubuntu 系统下 Docker 的配置文件是/etc/default/docker，CentOS 系统配置文件存放在/etc/sysconfig/docker </p></li><li><p>如何更改 Docker 的默认存储设置？<br>答：Docker 的默认存放位置是/var/lib/docker,如果希望将 Docker 的本地文件存储到其他分区，可以使用 Linux 软连接的方式来做。 </p></li></ol><p>Docker 与虚拟化 </p><ol><li><p>Docker 与 LXC（Linux Container）有何不同？<br>答：LXC 利用 Linux 上相关技术实现容器，Docker 则在如下的几个方面进行了改进：<br>l  移植性：通过抽象容器配置，容器可以实现一个平台移植到另一个平台；<br>l  镜像系统：基于 AUFS 的镜像系统为容器的分发带来了很多的便利，同时共同的<br>镜像层只需要存储一份，实现高效率的存储；<br>l  版本管理：类似于 GIT 的版本管理理念，用户可以更方面的创建、管理镜像文件；<br>l  仓库系统：仓库系统大大降低了镜像的分发和管理的成本；<br>l  周边工具：各种现有的工具（配置管理、云平台）对 Docker 的支持，以及基于<br>Docker 的 Pass、CI 等系统，让 Docker 的应用更加方便和多样化。 </p></li><li><p>Docker 与 Vagrant 有何不同？<br>答：两者的定位完全不同 Vagrant 类似于 Boot2Docker（一款运行 Docker 的最小内核），是一套虚拟机的管理环境，Vagrant 可以在多种系统上和虚拟机软件中运行，可以在 Windows。Mac等非 Linux 平台上为 Docker 支持，自身具有较好的包装性和移植性。 原生 Docker 自身只能运行在 Linux 平台上，但启动和运行的性能都比虚拟机要快，往往更适合快速开发和部署应用的场景。 </p></li><li><p>开发环境中 Docker 与 Vagrant 该如何选择？<br>答：Docker 不是虚拟机，而是进程隔离，对于资源的消耗很少，单一开发环境下Vagrant 是虚拟机上的封装，虚拟机本身会消耗资源。 </p></li></ol><p>Other FAQ </p><ol><li><p>Docker 能在非 Linux 平台（Windows+MacOS）上运行吗？<br>答：可以 </p></li><li><p>如何将一台宿主机的 docker 环境迁移到另外一台宿主机？<br>答：停止 Docker 服务，将整个 docker 存储文件复制到另外一台宿主机上，然后调整另外一台宿主机的配置即可 </p></li><li><p>Docker 容器创建后，删除了/var/run/netns 目录下的网络名字空间文件，可以手动恢复它：<br>答：查看容器进程 ID，比如 1234 </p><figure class="highlight shell"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs shell">sudo docker inspect --format=&#x27;&#123;&#123;. State.pid&#125;&#125;&#x27; $container_id <br>1234 <br></code></pre></td></tr></table></figure><p>到 proc 目录下，把对应的网络名字空间文件链接到/var/run/netns,然后通过正常的系统命令查看操作容器的名字空间。 </p></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>kubernetes1.23安装</title>
    <link href="/2022/01/17/kubernetes1-23%E5%AE%89%E8%A3%85/"/>
    <url>/2022/01/17/kubernetes1-23%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes简介"><a href="#Kubernetes简介" class="headerlink" title="Kubernetes简介"></a>Kubernetes简介</h1><p>Kubernetes（简称K8S）是开源的容器集群管理系统，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。它既是一款容器编排工具，也是全新的基于容器技术的分布式架构领先方案。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等功能，提高了大规模容器集群管理的便捷性。</p><p>K8S集群中有管理节点与工作节点两种类型。管理节点主要负责K8S集群管理，集群中各节点间的信息交互、任务调度，还负责容器、Pod、NameSpaces、PV等生命周期的管理。工作节点主要为容器和Pod提供计算资源，Pod及容器全部运行在工作节点上，工作节点通过kubelet服务与管理节点通信以管理容器的生命周期，并与集群其他节点进行通信。</p><p><img src="/images/image-20220117145808492.png" alt="image"></p><h1 id="一、-环境准备"><a href="#一、-环境准备" class="headerlink" title="一、  环境准备"></a>一、  环境准备</h1><p>Kubernetes支持在物理服务器或虚拟机中运行，本次使用虚拟机准备测试环境，硬件配置信息如表所示：</p><table><thead><tr><th>IP地址</th><th>节点角色</th><th>CPU</th><th>Memory</th><th>Hostname</th><th>磁盘</th></tr></thead><tbody><tr><td>10.0.201.1</td><td>master</td><td>&gt;=2c</td><td>&gt;=2G</td><td>k8s-01</td><td>sda、sdb</td></tr><tr><td>10.0.201.2</td><td>worker</td><td>&gt;=2c</td><td>&gt;=2G</td><td>k8s-02</td><td>sda、sdb</td></tr><tr><td>10.0.201.3</td><td>worker</td><td>&gt;=2c</td><td>&gt;=2G</td><td>k8s-03</td><td>sda、sdb</td></tr></tbody></table><p>注：在所有节点上进行如下操作</p><p>1.编辑 /etc/hosts 文件，添加域名解析。</p><figure class="highlight shell"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><pre><code class="hljs shell">cat &lt;`&lt;EOF &gt;`&gt;/etc/hosts<br>10.0.201.1 k8s-01<br>10.0.201.2 k8s-02<br>10.0.201.3 k8s-03<br>EOF<br></code></pre></td></tr></table></figure><p>2.关闭防火墙、selinux和swap。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl stop firewalld<br>systemctl disable firewalld<br>setenforce 0<br>sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config<br>swapoff -a<br>sed -i &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab<br></code></pre></td></tr></table></figure><p>3.配置国内yum源</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh">yum install -y wget<br>mkdir /etc/yum.repos.d/bak &amp;&amp; mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak<br>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.cloud.tencent.com/repo/centos7_base.repo<br>wget -O /etc/yum.repos.d/epel.repo http://mirrors.cloud.tencent.com/repo/epel-7.repo<br>yum clean all &amp;&amp; yum makecache<br></code></pre></td></tr></table></figure><h1 id="二、-前置检查"><a href="#二、-前置检查" class="headerlink" title="二、  前置检查"></a>二、  前置检查</h1><p>1、允许 iptables 检查桥接流量</p><p>确保 br_netfilter 模块被加载。运行 lsmod | grep br_netfilter 来检查。加载该模块，执行 sudo modprobe br_netfilter。</p><p>2、为了让你的 Linux 节点上的 iptables 能够正确地查看桥接流量，你需要确保在你的 sysctl 配置中将 net.bridge.bridge-nf-call-iptables 设置为 1。例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf<br>br_netfilter<br>EOF<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf<br>net.bridge.bridge-nf-call-ip6tables = 1<br>net.bridge.bridge-nf-call-iptables = 1<br>EOF<br>sudo sysctl --system<br></code></pre></td></tr></table></figure><h1 id="三、-软件安装"><a href="#三、-软件安装" class="headerlink" title="三、  软件安装"></a>三、  软件安装</h1><p>注：在所有节点上进行如下操作</p><p>1.安装docker</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo yum install -y yum-utils<br>sudo yum-config-manager \<br>  --add-repo \<br>  https://download.docker.com/linux/centos/docker-ce.repo<br>sudo yum install docker-ce docker-ce-cli containerd.io<br></code></pre></td></tr></table></figure><p>修改docker的cgroup driver为systemd</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">cat &lt;&lt;<span class="hljs-string">EOF &gt; /etc/docker/daemon.json</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">EOF</span><br><br>sudo systemctl start docker<br>systemctl <span class="hljs-built_in">enable</span> docker.service<br></code></pre></td></tr></table></figure><p>docker服务为容器运行提供计算资源，是所有容器运行的基本平台。</p><p>2.安装kubeadm、kubelet、kubectl</p><p>配置国内Kubernetes源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat &lt;`&lt;EOF &gt;` /etc/yum.repos.d/kubernetes.repo<br>[kubernetes]<br>name=Kubernetes<br>baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/<br>enabled=1<br>gpgcheck=1<br>repo_gpgcheck=1<br>gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg<br>EOF<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes<br>systemctl enable --now kubelet<br></code></pre></td></tr></table></figure><p>Kubelet负责与其他节点集群通信，并进行本节点Pod和容器生命周期的管理。<a href="https://www.kubernetes.org.cn/tags/kubeadm">Kubeadm</a>是Kubernetes的自动化部署工具，降低了部署难度，提高效率。Kubectl是Kubernetes集群管理工具。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl daemon-reload<br>systemctl restart kubelet<br></code></pre></td></tr></table></figure><h1 id="四、-部署master-节点"><a href="#四、-部署master-节点" class="headerlink" title="四、  部署master 节点"></a>四、  部署master 节点</h1><p>注：在master节点上进行如下操作</p><p>1.在master进行Kubernetes集群初始化。</p><p>使用 <code>flannel</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">kubeadm init --apiserver-advertise-address=10.0.201.1 \<br>--image-repository registry.aliyuncs.com/google_containers \<br>--service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16 \<br>--control-plane-endpoint=k8s.dabing.space<br>````<br>定义POD的网段为: 10.244.0.0/16， api server地址就是master本机IP地址。<br><br>这一步很关键，由于kubeadm 默认从官网k8s.grc.io下载所需镜像，国内无法访问，因此需要通过–image-repository指定阿里云镜像仓库地址，很多新手初次部署都卡在此环节无法进行后续配置。<br><br>用–control-plane-endpoint 参数指定apiserver的域名和端口，好处是后面如果要做kubernetes master node的HA，会有多个apiserver 服务器，可以用DNS做轮询或用HAproxy 做负载均衡。用域名加端口就不用在后面去改证书。kubernetes 为提升安全性，内部相互访问都会使用证书认证，这些证书会绑定IP或域名，如果直接用IP地址，后面改动–control-plane-endpoint中的IP指向，会要重新生成这些证书，而用域名就没有这个问题了，可以随时改动域名指向的IP<br><br>如果以非root 用户运行kubectl执行以下命令<br><br>```shell<br>mkdir -p $HOME/.kube<br>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config<br>sudo chown  $(id -u):$(id -g) $HOME/.kube/config<br></code></pre></td></tr></table></figure><p>如果使用root用户:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">export KUBECONFIG=/etc/kubernetes/admin.conf<br></code></pre></td></tr></table></figure><p>pod网络组件选择一种</p><p>flannel</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml<br></code></pre></td></tr></table></figure><p>Calico</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">curl https://docs.projectcalico.org/manifests/calico.yaml -O<br>kubectl apply -f calico.yaml<br>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml<br>kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml<br></code></pre></td></tr></table></figure><p>cidr: 192.168.0.0/16 替换为 cidr: 10.244.0.0/16</p><p>记录生成的最后部分内容，此内容需要在其它节点加入Kubernetes集群时执行。</p><p>添加控制节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">kubeadm join k8s.dabing.space:6443 --token 52osia.mqhmkakgvihmykhb \<br>--discovery-token-ca-cert-hash sha256:6170b77c1883e760b*********************************6bdeedaa1b8b93 \<br>--control-plane<br></code></pre></td></tr></table></figure><p>添加计算节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">kubeadm join k8s.dabing.space:6443 --token 52osia.mqhmkakgvihmykhb \<br>--discovery-token-ca-cert-hash sha256:6170b77c1883e760b*********************************6bdeedaa1b8b93<br></code></pre></td></tr></table></figure><p>token 查询：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubeadm token list<br></code></pre></td></tr></table></figure><p>token创建：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubeadm token create<br></code></pre></td></tr></table></figure><p>discovery-token-ca-cert-hash``生成：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">openssl x509 -pubkey -<span class="hljs-keyword">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | \<br>openssl dgst -sha256 -hex | sed <span class="hljs-string">&#x27;s/^.* //&#x27;</span><br></code></pre></td></tr></table></figure><p>2.配置kubectl工具</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir -p /root/.kube<br>cp /etc/kubernetes/admin.conf /root/.kube/config<br>kubectl get nodes<br>kubectl get cs<br></code></pre></td></tr></table></figure><h1 id="五、-集群状态检测"><a href="#五、-集群状态检测" class="headerlink" title="五、  集群状态检测"></a>五、  集群状态检测</h1><p>注：在master节点上进行如下操作</p><p>1.在master节点输入命令检查集群状态，返回如下结果则集群状态正常。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubectl get nodes<br><br>NAME   STATUS  ROLES  AGE   VERSION<br>master  Ready  master  26m   v1.14.2<br>node1  Ready  `&lt;none&gt;`  3m10s  v1.14.2<br>node2  Ready  `&lt;none&gt;`  3m   v1.14.2<br></code></pre></td></tr></table></figure><p>重点查看STATUS内容为Ready时，则说明集群状态正常。</p><p>2.创建Pod以验证集群是否正常。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">kubectl create deployment nginx --image=nginx<br>kubectl expose deployment nginx --port=80 --type=NodePort<br>kubectl get pod,svc<br></code></pre></td></tr></table></figure><h1 id="六、-部署Ingress"><a href="#六、-部署Ingress" class="headerlink" title="六、  部署Ingress"></a>六、  部署Ingress</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">helm upgrade --install ingress-nginx library/ingress-nginx \<br>--namespace ingress-nginx --create-namespace --<span class="hljs-built_in">set</span> controller.admissionWebhooks.enabled=<span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p>创建域名secret</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubectl create secret tls dabing.space-secret --cert=fullchain.pem --key=privkey.pem -n kubernetes-dashboard<br></code></pre></td></tr></table></figure><h1 id="七、-部署Dashboard"><a href="#七、-部署Dashboard" class="headerlink" title="七、  部署Dashboard"></a>七、  部署Dashboard</h1><p>注：在master节点上进行如下操作</p><p>2.部署Dashboard</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.4.0/aio/deploy/recommended.yaml<br></code></pre></td></tr></table></figure><p>运行proxy</p><p>[root@k8s-01 ~]# kubectl -n kubernetes-dashboard edit svc kubernetes-dashboard</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,</span><br><span class="hljs-comment"># and an empty file will abort the edit. If an error occurs while saving this file will be</span><br><span class="hljs-comment"># reopened with the relevant failures.</span><br><span class="hljs-comment">#</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">kubectl.kubernetes.io/last-applied-configuration:</span> <span class="hljs-string">|</span><br><span class="hljs-string">      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;k8s-app&quot;:&quot;kubernetes-dashboard&quot;&#125;,&quot;name&quot;:&quot;kubernetes-dashboard&quot;,&quot;namespace&quot;:&quot;kubernetes-dashboard&quot;&#125;,&quot;spec&quot;:&#123;&quot;ports&quot;:[&#123;&quot;port&quot;:443,&quot;targetPort&quot;:8443&#125;],&quot;selector&quot;:&#123;&quot;k8s-app&quot;:&quot;kubernetes-dashboard&quot;&#125;&#125;&#125;</span><br><span class="hljs-string"></span>  <span class="hljs-attr">creationTimestamp:</span> <span class="hljs-string">&quot;2019-11-08T07:56:44Z&quot;</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">k8s-app:</span> <span class="hljs-string">kubernetes-dashboard</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">kubernetes-dashboard</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br>  <span class="hljs-attr">resourceVersion:</span> <span class="hljs-string">&quot;5786&quot;</span><br>  <span class="hljs-attr">selfLink:</span> <span class="hljs-string">/api/v1/namespaces/kubernetes-dashboard/services/kubernetes-dashboard</span><br>  <span class="hljs-attr">uid:</span> <span class="hljs-string">f289c60d-040f-42cf-b18d-db8c621f0a2a</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">clusterIP:</span> <span class="hljs-number">10.1</span><span class="hljs-number">.167</span><span class="hljs-number">.91</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">port:</span> <span class="hljs-number">443</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br><span class="hljs-attr">targetPort:</span> <span class="hljs-number">8443</span><br><span class="hljs-attr">nodePort:</span> <span class="hljs-number">34430</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">k8s-app:</span> <span class="hljs-string">kubernetes-dashboard</span><br>  <span class="hljs-attr">sessionAffinity:</span> <span class="hljs-string">None</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span><br><span class="hljs-attr">status:</span><br>  <span class="hljs-attr">loadBalancer:</span> &#123;&#125;<br></code></pre></td></tr></table></figure><p>4.在浏览器输入Dashboard访问地址：<a href="http://10.0.201.1:34430/">http://10.0.201.1:34430</a></p><p>5.创建简单用户 <code>kubectl apply -f dashboard-adminuser.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRoleBinding</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br><span class="hljs-attr">roleRef:</span><br>  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span><br>  <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">cluster-admin</span><br><span class="hljs-attr">subjects:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br><br></code></pre></td></tr></table></figure><p>查询登录token</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">kubectl -n kubernetes-dashboard describe secret <span class="hljs-constructor">$(<span class="hljs-params">kubectl</span> -<span class="hljs-params">n</span> <span class="hljs-params">kubernetes</span>-<span class="hljs-params">dashboard</span> <span class="hljs-params">get</span> <span class="hljs-params">secret</span> | <span class="hljs-params">grep</span> <span class="hljs-params">admin</span>-<span class="hljs-params">user</span> | <span class="hljs-params">awk</span> &#x27;&#123;<span class="hljs-params">print</span> $1&#125;&#x27;)</span><br></code></pre></td></tr></table></figure><p>6.使用输出的token登录Dashboard。</p><p><img src="/images/clip_image002.jpg" alt="dashboard"></p><p>认证通过后，登录Dashboard首页如图</p><p><img src="/images/clip_image004.jpg" alt="dashboard"></p><p>暴漏dashboard 服务</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">Ingress</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="hljs-string">&quot;HTTPS&quot;</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">console</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">ingressClassName:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attr">rules:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">host:</span> <span class="hljs-string">dashboard.dabing.space</span><br>      <span class="hljs-attr">http:</span><br>        <span class="hljs-attr">paths:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">path:</span> <span class="hljs-string">/</span><br>            <span class="hljs-attr">pathType:</span> <span class="hljs-string">ImplementationSpecific</span><br>            <span class="hljs-attr">backend:</span><br>              <span class="hljs-attr">service:</span><br>                <span class="hljs-attr">name:</span> <span class="hljs-string">kubernetes-dashboard</span><br>                <span class="hljs-attr">port:</span><br>                  <span class="hljs-attr">number:</span> <span class="hljs-number">443</span><br>  <span class="hljs-attr">tls:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">hosts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">dashboard.dabing.space</span><br>      <span class="hljs-attr">secretName:</span> <span class="hljs-string">dabing.space-secret</span><br></code></pre></td></tr></table></figure><h1 id="八、-root-dir修改"><a href="#八、-root-dir修改" class="headerlink" title="八、  root-dir修改"></a>八、  root-dir修改</h1><p>修改root-dir</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">kubectl drain nodename<br>systemctl stop docker<br>systemctl stop kubelet<br></code></pre></td></tr></table></figure><p>修改/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf：</p><p>增加</p><p>Environment=”KUBELET_EXTRA_ARGS=$KUBELET_EXTRA_ARGS –root-dir=/data/k8s/kubelet/“</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">mv /var/lib/kubelet /data/k8s/<br>systemctl daemon-reload<br>systemctl start docker<br>systemctl start kubelet<br></code></pre></td></tr></table></figure><h1 id="九、-证书过期处理"><a href="#九、-证书过期处理" class="headerlink" title="九、  证书过期处理"></a>九、  证书过期处理</h1><p>现象：</p><p>[root@k8s-01 ~]# kubectl get nodes</p><p>Unable to connect to the server: x509: certificate has expired or is not yet valid</p><p>1.16版本，k8s内部强制默认采用https通信。部署时候生成的证书默认有效期就是一年</p><p>执行下列命令确认是否是证书过期问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@k8s-01 ~]# kubeadm alpha certs check-expiration<br><br>CERTIFICATE        EXPIRES         RESIDUAL TIME  EXTERNALLY MANAGED<br>admin.conf         Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>apiserver         Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>apiserver-etcd-client   Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>apiserver-kubelet-client  Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>controller-manager.conf  Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>etcd-healthcheck-client  Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>etcd-peer         Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>etcd-server        Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>front-proxy-client     Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br>scheduler.conf       Nov 27, 2020 09:07 UTC  `&lt;invalid&gt;`    no<br></code></pre></td></tr></table></figure><p>可以很清楚的看到：证书到29号就到期了。所以问题定位了。剩下的就是更新证书了</p><p>去官网查询更新证书方法，官方提供两种更新办法：</p><p>\1. upgrade版本</p><p>\2. 手工更新证书</p><p>更新步骤如下：</p><p>a) kubeadm alpha certs renew all</p><p>[root@k8s-01 ~]# kubeadm alpha certs renew all</p><p>certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed</p><p>certificate for serving the Kubernetes API renewed</p><p>certificate the apiserver uses to access etcd renewed</p><p>certificate for the API server to connect to kubelet renewed</p><p>certificate embedded in the kubeconfig file for the controller manager to use renewed</p><p>certificate for liveness probes to healthcheck etcd renewed</p><p>certificate for etcd nodes to communicate with each other renewed</p><p>certificate for serving etcd renewed</p><p>certificate for the front proxy client renewed</p><p>certificate embedded in the kubeconfig file for the scheduler manager to use renewed</p><p>执行完这一步再去看看证书，会发现已经都更新过了</p><p>[root@k8s-01 ~]# kubeadm alpha certs check-expiration</p><p>CERTIFICATE        EXPIRES         RESIDUAL TIME  EXTERNALLY MANAGED</p><p>admin.conf         Mar 08, 2022 11:07 UTC  364d      no</p><p>apiserver         Mar 08, 2022 11:07 UTC  364d      no</p><p>apiserver-etcd-client   Mar 08, 2022 11:07 UTC  364d      no</p><p>apiserver-kubelet-client  Mar 08, 2022 11:07 UTC  364d      no</p><p>controller-manager.conf  Mar 08, 2022 11:07 UTC  364d      no</p><p>etcd-healthcheck-client  Mar 08, 2022 11:07 UTC  364d      no</p><p>etcd-peer         Mar 08, 2022 11:07 UTC  364d      no</p><p>etcd-server        Mar 08, 2022 11:07 UTC  364d      no</p><p>front-proxy-client     Mar 08, 2022 11:07 UTC  364d      no</p><p>scheduler.conf       Mar 08, 2022 11:07 UTC  364d       no</p><p>b) kubeadm alpha kubeconfig user –apiserver-advertise-address 127.0.0.1 –client-name <a href="http://www.baidu.com/">www.baidu.com</a></p><p>这一步是更新配置kubelet配置文件，根据自己环境修改api的IP地址和主机域名</p><p>c）更新.kube文件</p><p>cp -i /etc/kubernetes/admin.conf ~/.kube/config</p><h1 id="十、-删除node"><a href="#十、-删除node" class="headerlink" title="十、  删除node"></a>十、  删除node</h1><p>kubectl drain k8s-02 –delete-emptydir-data –force –ignore-daemonsets</p><p>node节点执行</p><p>kubeadm reset</p><p>iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</p><p>kubectl delete node k8s-02</p><p>节点无法排水</p><p>error when evicting pods/“calico-typha-695fdb59b9-vppmh” -n “calico-system” (will retry after 5s): Cannot evict pod as it would violate the pod’s disruption budget</p><p>是 PDB（pod’s disruption budget）的特性，主动清理 Pod 时（例如 drain）对可用数量的保护，防止影响业务</p><p>扩容</p><p>kubectl scale –replicas=2 deploy/calico-typha -n calico-system</p><h1 id="十一、-NetworkPolicy示例"><a href="#十一、-NetworkPolicy示例" class="headerlink" title="十一、 NetworkPolicy示例"></a>十一、 NetworkPolicy示例</h1><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">kubectl</span> <span class="hljs-string">create</span> <span class="hljs-string">-f</span> <span class="hljs-bullet">-</span> <span class="hljs-string">&lt;&lt;EOF</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">NetworkPolicy</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">allow-dns-access</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">podSelector:</span><br>    <span class="hljs-attr">matchLabels:</span> &#123;&#125;<br>  <span class="hljs-attr">policyTypes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Egress</span><br>  <span class="hljs-attr">egress:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">to:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">namespaceSelector:</span><br>        <span class="hljs-attr">matchLabels:</span><br>          <span class="hljs-attr">kubernetes.io/metadata.name:</span> <span class="hljs-string">kube-system</span><br>    <span class="hljs-attr">ports:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">protocol:</span> <span class="hljs-string">UDP</span><br>      <span class="hljs-attr">port:</span> <span class="hljs-number">53</span><br><span class="hljs-string">EOF</span><br><br><br><span class="hljs-string">kubectl</span> <span class="hljs-string">create</span> <span class="hljs-string">-f</span> <span class="hljs-bullet">-</span> <span class="hljs-string">&lt;&lt;EOF</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">NetworkPolicy</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">allow-all</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">podSelector:</span> &#123;&#125;<br>  <span class="hljs-attr">ingress:</span><br>  <span class="hljs-bullet">-</span> &#123;&#125;<br>  <span class="hljs-attr">egress:</span><br>  <span class="hljs-bullet">-</span> &#123;&#125;<br>  <span class="hljs-attr">policyTypes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Ingress</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Egress</span><br><span class="hljs-string">EOF</span><br></code></pre></td></tr></table></figure><h1 id="十二、-Kubernetes-NFS-Client-Provisioner-安装"><a href="#十二、-Kubernetes-NFS-Client-Provisioner-安装" class="headerlink" title="十二、 Kubernetes NFS-Client Provisioner 安装"></a>十二、 Kubernetes NFS-Client Provisioner 安装</h1><p>helm install my-nfs-client-provisioner –set nfs.server=10.0.201.3 –set nfs.path=/storage stable/nfs-client-provisioner</p><p>注意 nfs 权限 /storage 10.0.201.0/24(rw,sync,no_root_squash,no_all_squash)</p><p>注：所有node</p><p>yum -y install nfs-utils rpcbind</p><p>错误：</p><p>Error: failed to download “incubator/nfs-client-provisioner” (hint: running <code>helm repo update</code> may help)</p><p>解决：</p><p>helm repo add stable <a href="https://kubernetes-charts.storage.googleapis.com/">https://kubernetes-charts.storage.googleapis.com/</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
